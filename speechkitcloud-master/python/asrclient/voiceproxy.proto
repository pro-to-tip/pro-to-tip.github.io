import "basic.proto";

package VoiceProxyProtobuf;

message MusicRequest
{
  message MusicParam
  {
    required string name = 1;

    required string value = 2;
  }

  // default options are "uid", "OAuth", "widget"
  repeated MusicParam musicProxyOptions = 1;
}

message AdvancedASROptions
{
  optional bool partial_results = 1 [default = true];

  optional float beam = 2 [default = -1];

  optional float lattice_beam = 3 [default = -1];

  optional int32 lattice_nbest = 4 [default = -1];

  optional int32 utterance_silence = 5 [default = 120];

  optional bool allow_multi_utt = 16 [default = true];

  optional int32 chunk_process_limit = 17 [default = 100];

  optional int32 cmn_window = 18 [default = 600];

  optional int32 cmn_latency = 19 [default = 150];

  optional bool capitalize = 20 [default = false];

  optional int32 expected_num_count = 21 [default = 0];
  
  repeated string grammar = 22;
  
  optional string srgs = 23;

  optional string biometry = 24;
}

message ConnectionRequest
{
  optional int32 protocolVersion = 1 [default = 1];

  // leave empty if you are not speechkit
  required string speechkitVersion = 2;

  required string serviceName = 3; // "asr_dictation", etc.

  required string uuid = 4;

  required string apiKey = 5;

  required string applicationName = 6;

  // vendor:model:type... user defined
  required string device = 7;

  // lat.lat,lan.lan
  required string coords = 8;

  // "general", "mapsyari", "freeform", "music"
  required string topic = 9;

  // "ru-RU"
  required string lang = 10;

  // "audio/x-speex", "audio/x-pcm;bit=16;rate=8000", etc.
  required string format =11;

  // enable punctuation mode for "freeform-dictation" topic
  optional bool punctuation = 12 [default = true];

  // data will also be send to music proxy, and optional AddDataResponse may happend with musicProxyResponse
  optional MusicRequest musicRequest = 17;

  optional bool disableAntimatNormalizer = 18 [default = false];

  optional AdvancedASROptions advancedASROptions = 19;

  optional bool skipAudioFromLogging = 20 [default = false];
}

///////////////////////////////////////////////////////////////////////////

message AddData
{
  optional bytes audioData = 1;

  required bool lastChunk = 2;
}

///////////////////////////////////////////////////////////////////////////

message AlignInfo
{
  optional float start_time = 1;

  optional float end_time = 2;

  optional float acoustic_score = 3;

  optional float graph_score = 4;

  optional float lm_score = 5;

  optional float total_score = 6;
}

message Word
{
  required float confidence = 1;

  required string value = 2;

  optional VoiceProxyProtobuf.AlignInfo align_info = 3;
}

message Result
{
  required float confidence = 1;

  repeated Word words = 2;

  optional string normalized = 3;

  optional VoiceProxyProtobuf.AlignInfo align_info = 4;
}

message BiometryResult
{
    required string classname = 1;

    required float confidence = 2;

    optional string tag = 3;
}

message AddDataResponse
{
  required BasicProtobuf.ConnectionResponse.ResponseCode responseCode = 1;

  repeated Result recognition = 2;

  // if true : recognition contains fully parsed N-best list (n results with n words)
  // otherwise recognition contains just 1 result 1 word with current "partical result"
  optional bool endOfUtt = 3 [default = false];

  // how many AddData requests were merged for this response
  optional int32 messagesCount = 4 [default = 1];

  // if not empty messageCounter should be 0
  optional string musicProxyResponse = 5;

  repeated BiometryResult bioResult = 6;
}


